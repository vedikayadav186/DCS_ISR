{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26pCeK5gs0E-",
        "outputId": "0d04755d-b8a1-41c9-bf3b-b107a3cd8fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.500\n",
            "Recall: 1.000\n",
            "F-measure: 0.667\n",
            "E-measure: 0.333\n",
            "NDCG: 0.889\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Load Excel dataset\n",
        "df = pd.read_excel(\"cranfield_q1_dataset.xlsx\")\n",
        "\n",
        "# Filter only query q1\n",
        "df_q1 = df[df[\"Query ID\"] == \"q1\"].sort_values(\"Rank\")\n",
        "\n",
        "# Retrieved and relevant sets\n",
        "retrieved = df_q1[\"Document ID\"].tolist()\n",
        "relevant = set(df_q1[df_q1[\"Is_Relevant\"] == \"Yes\"][\"Document ID\"].tolist())\n",
        "\n",
        "# Precision\n",
        "def precision(retrieved, relevant):\n",
        "    if not retrieved: return 0\n",
        "    return sum(doc in relevant for doc in retrieved) / len(retrieved)\n",
        "\n",
        "# Recall\n",
        "def recall(retrieved, relevant):\n",
        "    if not relevant: return 0\n",
        "    return sum(doc in relevant for doc in retrieved) / len(relevant)\n",
        "\n",
        "# F-measure\n",
        "def f_measure(p, r):\n",
        "    if (p + r) == 0: return 0\n",
        "    return 2 * p * r / (p + r)\n",
        "\n",
        "# E-measure\n",
        "def e_measure(p, r, beta=1):\n",
        "    if p == 0 and r == 0: return 1\n",
        "    return 1 - ((1 + beta**2) * p * r) / (beta**2 * p + r)\n",
        "\n",
        "# DCG\n",
        "dcg = sum(1 / math.log2(i+2) for i, d in enumerate(retrieved) if d in relevant)\n",
        "idcg = sum(1 / math.log2(i+2) for i in range(min(len(relevant), len(retrieved))))\n",
        "ndcg = dcg / idcg if idcg else 0\n",
        "\n",
        "# ---- Run metrics ----\n",
        "p = precision(retrieved, relevant)\n",
        "r = recall(retrieved, relevant)\n",
        "f = f_measure(p, r)\n",
        "e = e_measure(p, r)\n",
        "\n",
        "print(f\"Precision: {p:.3f}\")\n",
        "print(f\"Recall: {r:.3f}\")\n",
        "print(f\"F-measure: {f:.3f}\")\n",
        "print(f\"E-measure: {e:.3f}\")\n",
        "print(f\"NDCG: {ndcg:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisionn: 0.500\n",
            "Recalll: 1.000\n",
            "F_Mesaureeee: 0.667\n",
            "E_Measureee: 0.333\n",
            "NDCGGG: 0.889\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "df = pd.read_excel(\"cranfield_q1_dataset.xlsx\")\n",
        "\n",
        "\n",
        "df_q1 = df[df[\"Query ID\"] == \"q1\"].sort_values(\"Rank\")\n",
        "retrieved = df_q1[\"Document ID\"]\n",
        "relevant = set(df_q1[df_q1[\"Is_Relevant\"] == \"Yes\"][\"Document ID\"])\n",
        "\n",
        "def precision (retrieved, relevant):\n",
        "    if not len(retrieved): return 0\n",
        "    return sum(doc in relevant for doc in retrieved) / len(retrieved)\n",
        "\n",
        "def recall (retrieved, relevant):\n",
        "    if not len(relevant): return 0\n",
        "    return sum(doc in relevant for doc in retrieved) / len(relevant)\n",
        "\n",
        "def f_measure (p,r):\n",
        "    if (p+r) == 0: return 0\n",
        "    return (2*p*r)/(p+r)\n",
        "\n",
        "def e_measure (p,r, beta = 1):\n",
        "    if p == 0 and r == 0: return 1\n",
        "    return 1 - ((1 + beta **2) *p*r)/(beta**2 *p + r)\n",
        "\n",
        "dcg = sum (1 / math.log2(i+2) for i, doc in enumerate(retrieved) if doc in relevant)\n",
        "idcg = sum(1 / math.log2(i+2) for i in range(min(len(retrieved), len(relevant))))\n",
        "ndcg = dcg / idcg if idcg else 0\n",
        "\n",
        "p = precision (retrieved, relevant)\n",
        "r = recall (retrieved, relevant)\n",
        "f = f_measure (p,r)\n",
        "e = e_measure (p,r)\n",
        "\n",
        "print(f\"Precisionn: {p:.3f}\")\n",
        "print(f\"Recalll: {r:.3f}\")\n",
        "print(f\"F_Mesaureeee: {f:.3f}\")\n",
        "print(f\"E_Measureee: {e:.3f}\")\n",
        "print(f\"NDCGGG: {ndcg:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.500\n",
            "Recall: 1.000\n",
            "F-measure: 0.667\n",
            "E-measure: 0.333\n",
            "NDCG: 0.889\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "df = pd.read_excel(\"cranfield_q1_dataset.xlsx\")\n",
        "\n",
        "# Filter query q1 and lists\n",
        "df_q1 = df[df[\"Query ID\"] == \"q1\"].sort_values(\"Rank\")\n",
        "retrieved = df_q1[\"Document ID\"]\n",
        "relevant = set(df_q1[df_q1[\"Is_Relevant\"] == \"Yes\"][\"Document ID\"])\n",
        "\n",
        "# Precision, Recall, F, E\n",
        "tp = sum(retrieved.isin(relevant))\n",
        "p = tp / len(retrieved) if len(retrieved) else 0\n",
        "r = tp / len(relevant) if len(relevant) else 0\n",
        "f = 2*p*r/(p+r) if p+r else 0\n",
        "e = 1 - (2*p*r/(p+r)) if p+r else 1   # E-measure (Î²=1)\n",
        "\n",
        "# NDCG\n",
        "dcg = sum(1 / math.log2(i+2) for i, d in enumerate(retrieved) if d in relevant)\n",
        "idcg = sum(1 / math.log2(i+2) for i in range(min(len(relevant), len(retrieved))))\n",
        "ndcg = dcg / idcg if idcg else 0\n",
        "\n",
        "print(f\"Precision: {p:.3f}\")\n",
        "print(f\"Recall: {r:.3f}\")\n",
        "print(f\"F-measure: {f:.3f}\")\n",
        "print(f\"E-measure: {e:.3f}\")\n",
        "print(f\"NDCG: {ndcg:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
